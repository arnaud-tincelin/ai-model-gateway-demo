{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88f5c15d",
   "metadata": {},
   "source": [
    "# AI Model Gateway Demo - Deployment Notebook\n",
    "\n",
    "This notebook orchestrates the full deployment of the AI Model Gateway infrastructure and agents.\n",
    "\n",
    "## Features:\n",
    "- **Gold Agent**: Unlimited access, no rate limiting\n",
    "- **Bronze Agent**: Token rate limited (1000 tokens per minute)\n",
    "- **Token Metrics**: All requests emit token usage metrics to Application Insights\n",
    "\n",
    "## Steps:\n",
    "1. Deploy `infra/hub` - API Management with Gold/Bronze products and Azure OpenAI resources\n",
    "2. Deploy `infra/spoke` - AI Foundry project with Gold/Bronze Model Gateway connections\n",
    "3. Generate `.env` file from Terraform outputs\n",
    "4. Deploy and test both Gold and Bronze agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b7a7b2",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dbec60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (skip if already installed)\n",
    "%pip install -q \"azure-ai-projects>=2.0.0b3\" \"azure-identity>=1.25.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9320bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "LOCATION = \"swedencentral\"\n",
    "HUB_DIR = \"infra/hub\"\n",
    "SPOKE_DIR = \"infra/spoke\"\n",
    "os.environ[\"ARM_SUBSCRIPTION_ID\"] = \"\"\n",
    "os.environ[\"ARM_TENANT_ID\"] = \"\"\n",
    "os.environ[\"AZURE_TENANT_ID\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cbb79e",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cf409a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_terraform(working_dir: str, command: list[str], capture_output: bool = False) -> subprocess.CompletedProcess:\n",
    "    \"\"\"Run a terraform command in the specified directory.\"\"\"\n",
    "    full_command = [\"terraform\"] + command\n",
    "    print(f\"üìÇ {working_dir}\")\n",
    "    print(f\"üîß Running: {' '.join(full_command)}\")\n",
    "\n",
    "    result = subprocess.run(\n",
    "        full_command,\n",
    "        cwd=working_dir,\n",
    "        capture_output=capture_output,\n",
    "        text=True\n",
    "    )\n",
    "\n",
    "    if result.returncode != 0 and not capture_output:\n",
    "        raise Exception(f\"Terraform command failed with exit code {result.returncode}\")\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_terraform_output(working_dir: str) -> dict:\n",
    "    \"\"\"Get terraform outputs as a dictionary.\"\"\"\n",
    "    result = run_terraform(working_dir, [\"output\", \"-json\"], capture_output=True)\n",
    "    if result.returncode != 0:\n",
    "        raise Exception(f\"Failed to get outputs: {result.stderr}\")\n",
    "\n",
    "    outputs = json.loads(result.stdout)\n",
    "    # Extract just the values\n",
    "    return {k: v[\"value\"] for k, v in outputs.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e66b0b1",
   "metadata": {},
   "source": [
    "## Step 1: Deploy Hub Infrastructure\n",
    "\n",
    "This deploys:\n",
    "- Azure API Management\n",
    "- Azure OpenAI with model deployments\n",
    "- Application Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df04fbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Hub\n",
    "run_terraform(HUB_DIR, [\"init\", \"-upgrade\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ff508f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Hub deployment\n",
    "run_terraform(HUB_DIR, [\n",
    "    \"apply\",\n",
    "    \"-auto-approve\",\n",
    "    f\"-var=location={LOCATION}\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b33575f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Hub outputs\n",
    "hub_outputs = get_terraform_output(HUB_DIR)\n",
    "print(\"\\n‚úÖ Hub outputs:\")\n",
    "for key, value in hub_outputs.items():\n",
    "    if \"key\" in key.lower():\n",
    "        print(f\"   {key}: ***REDACTED***\")\n",
    "    else:\n",
    "        print(f\"   {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325c6209",
   "metadata": {},
   "source": [
    "## Step 2: Deploy Spoke Infrastructure\n",
    "\n",
    "This deploys:\n",
    "- AI Foundry Account and Project\n",
    "- Model Gateway connection to APIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f3bbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Spoke\n",
    "run_terraform(SPOKE_DIR, [\"init\", \"-upgrade\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7500dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare spoke variables from hub outputs - Gold and Bronze connections\n",
    "model_gateway_metadata = {\n",
    "    \"url\": hub_outputs[\"azure_openai_endpoint\"],\n",
    "    \"metadata\": hub_outputs[\"model_gateway_metadata\"]\n",
    "}\n",
    "\n",
    "model_gateway_gold_var = json.dumps({\n",
    "    \"url\": hub_outputs[\"azure_openai_endpoint\"],\n",
    "    \"api_key\": hub_outputs[\"gold_subscription_key\"],\n",
    "    \"metadata\": hub_outputs[\"model_gateway_metadata\"]\n",
    "})\n",
    "\n",
    "model_gateway_bronze_var = json.dumps({\n",
    "    \"url\": hub_outputs[\"azure_openai_endpoint\"],\n",
    "    \"api_key\": hub_outputs[\"bronze_subscription_key\"],\n",
    "    \"metadata\": hub_outputs[\"model_gateway_metadata\"]\n",
    "})\n",
    "\n",
    "# Apply Spoke deployment with Gold and Bronze connections\n",
    "run_terraform(SPOKE_DIR, [\n",
    "    \"apply\",\n",
    "    \"-auto-approve\",\n",
    "    f\"-var=resource_group_name={hub_outputs['resource_group_name']}\",\n",
    "    f\"-var=location={LOCATION}\",\n",
    "    f\"-var=model_gateway_gold={model_gateway_gold_var}\",\n",
    "    f\"-var=model_gateway_bronze={model_gateway_bronze_var}\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2767a00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Spoke outputs\n",
    "spoke_outputs = get_terraform_output(SPOKE_DIR)\n",
    "print(\"\\n‚úÖ Spoke outputs:\")\n",
    "for key, value in spoke_outputs.items():\n",
    "    print(f\"   {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57188726",
   "metadata": {},
   "source": [
    "## Step 3: Generate .env File\n",
    "\n",
    "Create the `.env` file required by `deploy_agent.py` and `test_agent.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3a3ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate .env content\n",
    "env_content = f\"\"\"# Auto-generated by deployment notebook - do not edit manually\n",
    "\n",
    "# Azure Configuration\n",
    "AZURE_SUBSCRIPTION_ID={os.environ['ARM_SUBSCRIPTION_ID']}\n",
    "AZURE_RESOURCE_GROUP={hub_outputs['resource_group_name']}\n",
    "\n",
    "# AI Foundry Configuration\n",
    "AZURE_AI_ACCOUNT_NAME={spoke_outputs['cognitive_account_name']}\n",
    "AZURE_AI_PROJECT_NAME={spoke_outputs['project_name']}\n",
    "AZURE_AI_PROJECT_ENDPOINT={spoke_outputs['project_endpoint']}\n",
    "\n",
    "# Agent Configuration - Gold (no rate limiting)\n",
    "AGENT_NAME_GOLD=GoldAgent\n",
    "AGENT_MODEL_GOLD=model-gateway-gold/gpt-4o-mini\n",
    "\n",
    "# Agent Configuration - Bronze (token rate limited)\n",
    "AGENT_NAME_BRONZE=BronzeAgent\n",
    "AGENT_MODEL_BRONZE=model-gateway-bronze/gpt-4o-mini\n",
    "\"\"\"\n",
    "\n",
    "# Write .env file\n",
    "with open(\".env\", \"w\") as f:\n",
    "    f.write(env_content)\n",
    "\n",
    "print(\"‚úÖ Generated .env file:\")\n",
    "print(\"-\" * 40)\n",
    "# Print without sensitive data\n",
    "for line in env_content.split(\"\\n\"):\n",
    "    if line and not line.startswith(\"#\"):\n",
    "        print(f\"   {line}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9d10bb",
   "metadata": {},
   "source": [
    "## Step 4: Deploy Gold and Bronze Agents\n",
    "\n",
    "Create both agents in AI Foundry:\n",
    "- **Gold Agent**: Uses `model-gateway-gold` connection (no rate limiting)\n",
    "- **Bronze Agent**: Uses `model-gateway-bronze` connection (1000 tokens/minute limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d837d09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.projects.models import PromptAgentDefinition\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# Agent configurations\n",
    "AGENT_NAME_GOLD = \"GoldAgent\"\n",
    "AGENT_MODEL_GOLD = \"model-gateway-gold/gpt-4o-mini\"\n",
    "\n",
    "AGENT_NAME_BRONZE = \"BronzeAgent\"\n",
    "AGENT_MODEL_BRONZE = \"model-gateway-bronze/gpt-4o-mini\"\n",
    "\n",
    "print(\"üöÄ Deploying Agents via AI Gateway\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Initialize the project client\n",
    "print(\"\\nüì° Connecting to Azure AI Foundry project...\")\n",
    "print(f\"   Project: {spoke_outputs['project_name']}\")\n",
    "print(f\"   Endpoint: {spoke_outputs['project_endpoint']}\")\n",
    "\n",
    "project_client = AIProjectClient(\n",
    "    endpoint=spoke_outputs['project_endpoint'],\n",
    "    credential=DefaultAzureCredential()\n",
    ")\n",
    "print(\"‚úÖ Connected successfully\")\n",
    "\n",
    "with project_client:\n",
    "    # Create Gold Agent\n",
    "    print(\"\\nü•á Creating Gold Agent (no rate limiting)...\")\n",
    "    print(f\"   Model: {AGENT_MODEL_GOLD}\")\n",
    "\n",
    "    gold_agent = project_client.agents.create_version(\n",
    "        agent_name=AGENT_NAME_GOLD,\n",
    "        definition=PromptAgentDefinition(\n",
    "            model=AGENT_MODEL_GOLD,\n",
    "            instructions=\"You are a Gold tier AI assistant with unlimited access. \"\n",
    "            \"All your requests are routed through APIM with no rate limiting. \"\n",
    "            \"Token metrics are emitted to Application Insights for monitoring.\",\n",
    "        ),\n",
    "    )\n",
    "    print(f\"   ‚úÖ Gold Agent created: {gold_agent.name} (version {gold_agent.version})\")\n",
    "\n",
    "    # Create Bronze Agent\n",
    "    print(\"\\nü•â Creating Bronze Agent (token rate limited)...\")\n",
    "    print(f\"   Model: {AGENT_MODEL_BRONZE}\")\n",
    "\n",
    "    bronze_agent = project_client.agents.create_version(\n",
    "        agent_name=AGENT_NAME_BRONZE,\n",
    "        definition=PromptAgentDefinition(\n",
    "            model=AGENT_MODEL_BRONZE,\n",
    "            instructions=\"You are a Bronze tier AI assistant with rate limited access. \"\n",
    "            \"Your requests are limited to 1000 tokens per minute through APIM. \"\n",
    "            \"Token metrics are emitted to Application Insights for monitoring.\",\n",
    "        ),\n",
    "    )\n",
    "    print(f\"   ‚úÖ Bronze Agent created: {bronze_agent.name} (version {bronze_agent.version})\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üéâ Agent Deployment Complete!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nüìã Agent Summary:\")\n",
    "print(f\"   ü•á Gold Agent: {gold_agent.name} v{gold_agent.version} - No rate limiting\")\n",
    "print(f\"   ü•â Bronze Agent: {bronze_agent.name} v{bronze_agent.version} - 1000 tokens/min limit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edee436e",
   "metadata": {},
   "source": [
    "## Step 5: Test Agents\n",
    "\n",
    "Test both Gold and Bronze agents through the APIM gateway to verify:\n",
    "- Token metrics are being emitted to Application Insights\n",
    "- Gold agent has no rate limits\n",
    "- Bronze agent respects the 1000 tokens/minute limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e922633",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üß™ Testing APIM Gateway Agents\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "project_client = AIProjectClient(\n",
    "    endpoint=spoke_outputs['project_endpoint'],\n",
    "    credential=DefaultAzureCredential()\n",
    ")\n",
    "\n",
    "def test_agent(agent_name, agent_version, tier_name, tier_emoji):\n",
    "    \"\"\"Test an agent and display results\"\"\"\n",
    "    print(f\"\\n{tier_emoji} Testing {tier_name} Agent: {agent_name} (v{agent_version})\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    test_message = f\"Hello! You are the {tier_name} agent. Please tell me a very short joke about API rate limits.\"\n",
    "    print(f\"üí¨ User: {test_message}\")\n",
    "\n",
    "    with project_client.get_openai_client() as openai_client:\n",
    "        # Create a conversation with initial user message\n",
    "        conversation = openai_client.conversations.create(\n",
    "            items=[{\"type\": \"message\", \"role\": \"user\", \"content\": test_message}],\n",
    "        )\n",
    "\n",
    "        # Get response from agent\n",
    "        response = openai_client.responses.create(\n",
    "            conversation=conversation.id,\n",
    "            extra_body={\"agent\": {\"name\": agent_name, \"type\": \"agent_reference\"}},\n",
    "            input=\"\",\n",
    "        )\n",
    "\n",
    "        print(f\"\\nü§ñ {tier_name} Agent Response:\")\n",
    "        print(f\"   {response.output_text}\")\n",
    "\n",
    "    return response\n",
    "\n",
    "with project_client:\n",
    "    # Test Gold Agent\n",
    "    gold_response = test_agent(gold_agent.name, gold_agent.version, \"Gold\", \"ü•á\")\n",
    "\n",
    "    # Test Bronze Agent\n",
    "    bronze_response = test_agent(bronze_agent.name, bronze_agent.version, \"Bronze\", \"ü•â\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ Tests Complete!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nüìä Request Flow (both agents):\")\n",
    "print(\"   1. Python SDK ‚Üí Azure AI Foundry Project\")\n",
    "print(\"   2. Foundry ‚Üí model-gateway-{gold|bronze} connection\")\n",
    "print(f\"   3. Connection ‚Üí APIM ({hub_outputs['apim_gateway_url']})\")\n",
    "print(\"   4. APIM applies product-specific policies:\")\n",
    "print(\"      - Gold: No rate limiting\")\n",
    "print(\"      - Bronze: 1000 tokens/minute limit (llm-token-limit)\")\n",
    "print(\"   5. Token metrics emitted to Application Insights (azure-openai-emit-token-metric)\")\n",
    "print(\"   6. APIM ‚Üí Azure OpenAI (via managed identity)\")\n",
    "print(\"   7. Response flows back through APIM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e50bfc9",
   "metadata": {},
   "source": [
    "## Step 6: Test Rate Limiting - Gold vs Bronze\n",
    "\n",
    "Make multiple rapid requests to both agents to demonstrate:\n",
    "- **Gold Agent**: No rate limiting - all requests succeed\n",
    "- **Bronze Agent**: Token rate limited - should get 429 errors after exceeding 1000 tokens/minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e9d06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "print(\"üß™ Testing Rate Limiting - Gold vs Bronze\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Long prompt to consume more tokens\n",
    "long_prompt = \"\"\"Please provide a detailed explanation of how API gateways work in enterprise architectures.\n",
    "Include information about load balancing, rate limiting, authentication, caching, and monitoring.\n",
    "Make your response comprehensive and detailed to demonstrate token consumption.\"\"\"\n",
    "\n",
    "def test_rate_limiting(agent_name, tier_name, tier_emoji, num_requests=10):\n",
    "    \"\"\"Test rate limiting on an agent\"\"\"\n",
    "    print(f\"\\n{tier_emoji} Testing {tier_name} Agent Rate Limiting\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Making {num_requests} requests to test token limit...\")\n",
    "\n",
    "    successful_requests = 0\n",
    "    rate_limited_requests = 0\n",
    "\n",
    "    # Create a fresh client for each test\n",
    "    client = AIProjectClient(\n",
    "        endpoint=spoke_outputs['project_endpoint'],\n",
    "        credential=DefaultAzureCredential()\n",
    "    )\n",
    "\n",
    "    with client:\n",
    "        with client.get_openai_client() as openai_client:\n",
    "            for i in range(num_requests):\n",
    "                try:\n",
    "                    print(f\"   üì§ Request {i+1}/{num_requests}...\", end=\" \")\n",
    "\n",
    "                    conversation = openai_client.conversations.create(\n",
    "                        items=[{\"type\": \"message\", \"role\": \"user\", \"content\": long_prompt}],\n",
    "                    )\n",
    "\n",
    "                    response = openai_client.responses.create(\n",
    "                        conversation=conversation.id,\n",
    "                        extra_body={\"agent\": {\"name\": agent_name, \"type\": \"agent_reference\"}},\n",
    "                        input=\"\",\n",
    "                    )\n",
    "\n",
    "                    successful_requests += 1\n",
    "                    print(f\"‚úÖ Success ({len(response.output_text)} chars)\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    if \"429\" in str(e) or \"Too Many Requests\" in str(e):\n",
    "                        rate_limited_requests += 1\n",
    "                        print(f\"üö´ Rate Limited (429)\")\n",
    "                    else:\n",
    "                        print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "                # Small delay between requests\n",
    "                time.sleep(1)\n",
    "\n",
    "    return successful_requests, rate_limited_requests\n",
    "\n",
    "# Test Gold Agent (no rate limiting)\n",
    "gold_success, gold_limited = test_rate_limiting(gold_agent.name, \"Gold\", \"ü•á\", num_requests=10)\n",
    "\n",
    "# Test Bronze Agent (1000 tokens/minute limit)\n",
    "bronze_success, bronze_limited = test_rate_limiting(bronze_agent.name, \"Bronze\", \"ü•â\", num_requests=10)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìä Rate Limiting Test Results:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nü•á Gold Agent (no rate limiting):\")\n",
    "print(f\"   ‚úÖ Successful requests: {gold_success}\")\n",
    "print(f\"   üö´ Rate limited requests: {gold_limited}\")\n",
    "\n",
    "print(f\"\\nü•â Bronze Agent (1000 tokens/minute limit):\")\n",
    "print(f\"   ‚úÖ Successful requests: {bronze_success}\")\n",
    "print(f\"   üö´ Rate limited requests: {bronze_limited}\")\n",
    "\n",
    "print(\"\\nüí° Expected behavior:\")\n",
    "print(\"   - Gold: All requests should succeed (no rate limiting)\")\n",
    "print(\"   - Bronze: Some requests should be rate limited after token quota exceeded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a51a8e7",
   "metadata": {},
   "source": [
    "## Cleanup (Optional)\n",
    "\n",
    "Destroy all infrastructure when done testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ec0323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ö†Ô∏è DANGER: Uncomment to destroy all resources\n",
    "# print(\"üóëÔ∏è Destroying Spoke...\")\n",
    "# run_terraform(SPOKE_DIR, [\"destroy\", \"-auto-approve\",\n",
    "#     f\"-var=resource_group_name={hub_outputs['resource_group_name']}\",\n",
    "#     f\"-var=location={LOCATION}\",\n",
    "#     f\"-var=model_gateway_gold={model_gateway_gold_var}\",\n",
    "#     f\"-var=model_gateway_bronze={model_gateway_bronze_var}\"\n",
    "# ])\n",
    "\n",
    "# print(\"üóëÔ∏è Destroying Hub...\")\n",
    "# run_terraform(HUB_DIR, [\"destroy\", \"-auto-approve\",\n",
    "#     f\"-var=location={LOCATION}\"\n",
    "# ])\n",
    "\n",
    "# print(\"‚úÖ All resources destroyed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
