{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88f5c15d",
   "metadata": {},
   "source": [
    "# AI Model Gateway Demo - Deployment Notebook\n",
    "\n",
    "This notebook orchestrates the full deployment of the AI Model Gateway infrastructure and agents.\n",
    "\n",
    "## Steps:\n",
    "1. Deploy `infra/hub` - API Management and Azure OpenAI resources\n",
    "2. Deploy `infra/spoke` - AI Foundry project with Model Gateway connection\n",
    "3. Generate `.env` file from Terraform outputs\n",
    "4. Deploy and test the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b7a7b2",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dbec60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (skip if already installed)\n",
    "%pip install -q \"azure-ai-projects>=2.0.0b3\" \"azure-identity>=1.25.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9320bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "LOCATION = \"swedencentral\"\n",
    "HUB_DIR = \"infra/hub\"\n",
    "SPOKE_DIR = \"infra/spoke\"\n",
    "os.environ[\"ARM_SUBSCRIPTION_ID\"] = \"\"\n",
    "os.environ[\"ARM_TENANT_ID\"] = \"\"\n",
    "os.environ[\"AZURE_TENANT_ID\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cbb79e",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cf409a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_terraform(working_dir: str, command: list[str], capture_output: bool = False) -> subprocess.CompletedProcess:\n",
    "    \"\"\"Run a terraform command in the specified directory.\"\"\"\n",
    "    full_command = [\"terraform\"] + command\n",
    "    print(f\"üìÇ {working_dir}\")\n",
    "    print(f\"üîß Running: {' '.join(full_command)}\")\n",
    "\n",
    "    result = subprocess.run(\n",
    "        full_command,\n",
    "        cwd=working_dir,\n",
    "        capture_output=capture_output,\n",
    "        text=True\n",
    "    )\n",
    "\n",
    "    if result.returncode != 0 and not capture_output:\n",
    "        raise Exception(f\"Terraform command failed with exit code {result.returncode}\")\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_terraform_output(working_dir: str) -> dict:\n",
    "    \"\"\"Get terraform outputs as a dictionary.\"\"\"\n",
    "    result = run_terraform(working_dir, [\"output\", \"-json\"], capture_output=True)\n",
    "    if result.returncode != 0:\n",
    "        raise Exception(f\"Failed to get outputs: {result.stderr}\")\n",
    "\n",
    "    outputs = json.loads(result.stdout)\n",
    "    # Extract just the values\n",
    "    return {k: v[\"value\"] for k, v in outputs.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e66b0b1",
   "metadata": {},
   "source": [
    "## Step 1: Deploy Hub Infrastructure\n",
    "\n",
    "This deploys:\n",
    "- Azure API Management\n",
    "- Azure OpenAI with model deployments\n",
    "- Application Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df04fbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Hub\n",
    "run_terraform(HUB_DIR, [\"init\", \"-upgrade\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ff508f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Hub deployment\n",
    "run_terraform(HUB_DIR, [\n",
    "    \"apply\",\n",
    "    \"-auto-approve\",\n",
    "    f\"-var=location={LOCATION}\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b33575f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Hub outputs\n",
    "hub_outputs = get_terraform_output(HUB_DIR)\n",
    "print(\"\\n‚úÖ Hub outputs:\")\n",
    "for key, value in hub_outputs.items():\n",
    "    if \"key\" in key.lower():\n",
    "        print(f\"   {key}: ***REDACTED***\")\n",
    "    else:\n",
    "        print(f\"   {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325c6209",
   "metadata": {},
   "source": [
    "## Step 2: Deploy Spoke Infrastructure\n",
    "\n",
    "This deploys:\n",
    "- AI Foundry Account and Project\n",
    "- Model Gateway connection to APIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f3bbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Spoke\n",
    "run_terraform(SPOKE_DIR, [\"init\", \"-upgrade\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7500dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare spoke variables from hub outputs\n",
    "model_gateway_var = json.dumps({\n",
    "    \"url\": hub_outputs[\"azure_openai_endpoint\"],\n",
    "    \"api_key\": hub_outputs[\"apim_subscription_key\"],\n",
    "    \"metadata\": hub_outputs[\"model_gateway_metadata\"]\n",
    "})\n",
    "\n",
    "# Apply Spoke deployment\n",
    "run_terraform(SPOKE_DIR, [\n",
    "    \"apply\",\n",
    "    \"-auto-approve\",\n",
    "    f\"-var=resource_group_name={hub_outputs['resource_group_name']}\",\n",
    "    f\"-var=location={LOCATION}\",\n",
    "    f\"-var=model_gateway={model_gateway_var}\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2767a00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Spoke outputs\n",
    "spoke_outputs = get_terraform_output(SPOKE_DIR)\n",
    "print(\"\\n‚úÖ Spoke outputs:\")\n",
    "for key, value in spoke_outputs.items():\n",
    "    print(f\"   {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57188726",
   "metadata": {},
   "source": [
    "## Step 3: Generate .env File\n",
    "\n",
    "Create the `.env` file required by `deploy_agent.py` and `test_agent.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3a3ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate .env content\n",
    "env_content = f\"\"\"# Auto-generated by deployment notebook - do not edit manually\n",
    "\n",
    "# Azure Configuration\n",
    "AZURE_SUBSCRIPTION_ID={os.environ['ARM_SUBSCRIPTION_ID']}\n",
    "AZURE_RESOURCE_GROUP={hub_outputs['resource_group_name']}\n",
    "\n",
    "# AI Foundry Configuration\n",
    "AZURE_AI_ACCOUNT_NAME={spoke_outputs['cognitive_account_name']}\n",
    "AZURE_AI_PROJECT_NAME={spoke_outputs['project_name']}\n",
    "AZURE_AI_PROJECT_ENDPOINT={spoke_outputs['project_endpoint']}\n",
    "\n",
    "# Agent Configuration\n",
    "AGENT_NAME=APIMGatewayAgent\n",
    "AGENT_MODEL=model-gateway/gpt-4o-mini\n",
    "\"\"\"\n",
    "\n",
    "# Write .env file\n",
    "with open(\".env\", \"w\") as f:\n",
    "    f.write(env_content)\n",
    "\n",
    "print(\"‚úÖ Generated .env file:\")\n",
    "print(\"-\" * 40)\n",
    "# Print without sensitive data\n",
    "for line in env_content.split(\"\\n\"):\n",
    "    if line and not line.startswith(\"#\"):\n",
    "        print(f\"   {line}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9d10bb",
   "metadata": {},
   "source": [
    "## Step 4: Deploy Agent\n",
    "\n",
    "Run `deploy_agent.py` to create the agent in AI Foundry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d837d09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.projects.models import PromptAgentDefinition\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# Agent configuration\n",
    "AGENT_NAME = \"APIMGatewayAgent\"\n",
    "AGENT_MODEL = \"model-gateway/gpt-4o-mini\"\n",
    "\n",
    "print(\"üöÄ Deploying Agent via AI Gateway\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Initialize the project client\n",
    "print(\"\\nüì° Connecting to Azure AI Foundry project...\")\n",
    "print(f\"   Project: {spoke_outputs['project_name']}\")\n",
    "print(f\"   Endpoint: {spoke_outputs['project_endpoint']}\")\n",
    "\n",
    "project_client = AIProjectClient(\n",
    "    endpoint=spoke_outputs['project_endpoint'],\n",
    "    credential=DefaultAzureCredential()\n",
    ")\n",
    "print(\"‚úÖ Connected successfully\")\n",
    "\n",
    "# Create an agent using the AI Gateway connection\n",
    "print(\"\\nü§ñ Creating agent with AI Gateway connection...\")\n",
    "print(f\"   Model: {AGENT_MODEL}\")\n",
    "print(\"   (This routes through APIM to Azure OpenAI)\")\n",
    "\n",
    "with project_client:\n",
    "    agent = project_client.agents.create_version(\n",
    "        agent_name=AGENT_NAME,\n",
    "        definition=PromptAgentDefinition(\n",
    "            model=AGENT_MODEL,\n",
    "            instructions=\"You are a helpful AI assistant deployed via Azure API Management. \"\n",
    "            \"All your requests are routed through APIM for monitoring and governance.\",\n",
    "        ),\n",
    "    )\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üéâ Agent Deployment Complete!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nüìã Agent Details:\")\n",
    "print(f\"   Agent Name: {agent.name}\")\n",
    "print(f\"   Agent Version: {agent.version}\")\n",
    "print(f\"   Model: {AGENT_MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edee436e",
   "metadata": {},
   "source": [
    "## Step 5: Test Agent\n",
    "\n",
    "Run `test_agent.py` to verify the agent works through the APIM gateway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e922633",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üß™ Testing APIM Gateway Prompt Agent\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "project_client = AIProjectClient(\n",
    "    endpoint=spoke_outputs['project_endpoint'],\n",
    "    credential=DefaultAzureCredential()\n",
    ")\n",
    "\n",
    "with project_client:\n",
    "    print(f\"\\nüìã Using Agent: {agent.name} (version {agent.version})\")\n",
    "    print(f\"   Model: {AGENT_MODEL}\")\n",
    "    print(\"   (Routes through APIM)\")\n",
    "\n",
    "    # Test message\n",
    "    test_message = \"Hello! Please tell me a short joke about AI and API gateways.\"\n",
    "    print(f\"\\nüí¨ User: {test_message}\")\n",
    "\n",
    "    print(\"\\nüîÑ Processing through APIM Gateway...\")\n",
    "\n",
    "    # Use the OpenAI client and Conversations/Responses API\n",
    "    with project_client.get_openai_client() as openai_client:\n",
    "        # Create a conversation with initial user message\n",
    "        conversation = openai_client.conversations.create(\n",
    "            items=[{\"type\": \"message\", \"role\": \"user\", \"content\": test_message}],\n",
    "        )\n",
    "        print(f\"   Conversation created: {conversation.id}\")\n",
    "\n",
    "        # Get response from agent\n",
    "        response = openai_client.responses.create(\n",
    "            conversation=conversation.id,\n",
    "            extra_body={\"agent\": {\"name\": agent.name, \"type\": \"agent_reference\"}},\n",
    "            input=\"\",\n",
    "        )\n",
    "\n",
    "        print(\"\\nü§ñ Assistant Response:\")\n",
    "        print(f\"   {response.output_text}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ Test Complete!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nüìä Request Flow:\")\n",
    "print(\"   1. Python SDK ‚Üí Azure AI Foundry Project\")\n",
    "print(\"   2. Foundry ‚Üí model-gateway connection\")\n",
    "print(f\"   3. Connection ‚Üí APIM ({hub_outputs['apim_gateway_url']})\")\n",
    "print(\"   4. APIM ‚Üí Azure OpenAI (via managed identity)\")\n",
    "print(\"   5. Response flows back through APIM (with monitoring/governance)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a51a8e7",
   "metadata": {},
   "source": [
    "## Cleanup (Optional)\n",
    "\n",
    "Destroy all infrastructure when done testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ec0323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ö†Ô∏è DANGER: Uncomment to destroy all resources\n",
    "# print(\"üóëÔ∏è Destroying Spoke...\")\n",
    "# run_terraform(SPOKE_DIR, [\"destroy\", \"-auto-approve\",\n",
    "#     f\"-var=resource_group_name={hub_outputs['resource_group_name']}\",\n",
    "#     f\"-var=location={LOCATION}\",\n",
    "#     f\"-var=model_gateway={model_gateway_var}\"\n",
    "# ])\n",
    "\n",
    "# print(\"üóëÔ∏è Destroying Hub...\")\n",
    "# run_terraform(HUB_DIR, [\"destroy\", \"-auto-approve\",\n",
    "#     f\"-var=location={LOCATION}\"\n",
    "# ])\n",
    "\n",
    "# print(\"‚úÖ All resources destroyed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
